{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a165f01f-070e-4fa0-ad3f-0bce8ae1ec2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 23:51:25.949941: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 23:51:25.956398: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 23:51:25.997559: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 23:51:27.227975: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from scipy.stats import sem, t\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from IPython.display import display, Math, Latex\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48419e-e468-4899-901d-a9724f7008cb",
   "metadata": {},
   "source": [
    "# An Additional Lecture on Sampling\n",
    "\n",
    "Sampling methods in machine learning play a crucial role in ensuring that the data used for training, validation, and testing are representative of the underlying population. Let's delve into some common types of sampling techniques used in machine learning:\n",
    "\n",
    "1. **Random Sampling**:\n",
    "   - Random sampling involves selecting a subset of data points from the entire dataset without any specific pattern or bias. \n",
    "   - Mathematically, each data point has an equal probability of being chosen.\n",
    "   - Random sampling is widely used when the dataset is large and uniformly distributed, ensuring that each sample is representative of the population.\n",
    "\n",
    "3. **Systematic Sampling**:\n",
    "   - Systematic sampling involves selecting data points at regular intervals from an ordered list of the population.\n",
    "   - The interval, also known as the sampling interval, is determined by dividing the total population size by the desired sample size.\n",
    "   - This method is efficient and straightforward but can introduce bias if there is an underlying pattern in the ordering of the data.\n",
    "\n",
    "2. **Stratified Sampling**:\n",
    "   - In stratified sampling, the dataset is divided into several homogeneous subgroups called strata based on certain characteristics.\n",
    "   - Samples are then randomly selected from each stratum proportionally to their size in the population.\n",
    "   - This technique ensures that each subgroup is represented adequately in the sample, which is crucial when certain subgroups are underrepresented in the dataset.\n",
    "\n",
    "4. **Cluster Sampling**:\n",
    "   - Cluster sampling involves dividing the population into clusters or groups and then randomly selecting entire clusters to be included in the sample.\n",
    "   - This method is particularly useful when it is impractical or expensive to sample individuals directly.\n",
    "   - However, cluster sampling can introduce bias if the clusters are not representative of the population or if there is heterogeneity within clusters.\n",
    "\n",
    "6. **Stratified Cluster Sampling**:\n",
    "   - This method combines the principles of stratified and cluster sampling by first dividing the population into strata and then selecting clusters within each stratum.\n",
    "   - It aims to capture the variability within strata while also accounting for the efficiency gained through cluster sampling.\n",
    "\n",
    "Each sampling method has its advantages and limitations, and the choice of method depends on various factors such as the nature of the data, the research objectives, and resource constraints. Understanding these sampling techniques is crucial for ensuring the reliability and generalizability of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f22971b-e7c0-46e9-bdb0-782d9008899a",
   "metadata": {},
   "source": [
    "## Random Sampling\n",
    "\n",
    "Ordinary random sampling, also known as simple random sampling, is one of the most straightforward and commonly used sampling techniques. In this method, each data point in the population has an equal probability of being selected, independently of other data points. This ensures that every possible sample of a given size has an equal chance of being selected, making the sample representative of the population as a whole.\n",
    "\n",
    "Ordinary random sampling is useful when the population is homogeneous, and there is no need for additional stratification or clustering. It is straightforward to implement and provides an unbiased representation of the population. However, it may not be suitable for datasets with specific characteristics, such as stratified or clustered populations, where other sampling methods like stratified or cluster sampling may be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f1b1c3-edaa-4aa8-af8b-c8098a815cbf",
   "metadata": {},
   "source": [
    "## Systematic Sampling\n",
    "\n",
    "Systematic sampling is a method of selecting data points from a population at regular intervals. In the context of time series data, systematic sampling involves selecting every kth data point from the time series, where k is the sampling interval. This method ensures that the selected samples are spread evenly across the entire time series, allowing for efficient and representative sampling.\n",
    "\n",
    "Suppose we have a time series dataset with timestamps as index. Let's create a sample time series dataset for demonstration. Then we will use a sampling interval of length 3, i.e. we will use every 3rd data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a8a1f9-dfcc-4843-bb72-678114403a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-01</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-02</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-03</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-04</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-05</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-06</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-07</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-08</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-09</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-10</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            value\n",
       "timestamp        \n",
       "2024-03-01     10\n",
       "2024-03-02     20\n",
       "2024-03-03     30\n",
       "2024-03-04     40\n",
       "2024-03-05     50\n",
       "2024-03-06     60\n",
       "2024-03-07     70\n",
       "2024-03-08     80\n",
       "2024-03-09     90\n",
       "2024-03-10    100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'value': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'timestamp': pd.date_range(start='2024-03-01', periods=10, freq='D')\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('timestamp', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5292735f-9c1d-4bb8-ac3f-5df605d9c164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Systematic Sample:\n",
      "            value\n",
      "timestamp        \n",
      "2024-03-01     10\n",
      "2024-03-04     40\n",
      "2024-03-07     70\n",
      "2024-03-10    100\n"
     ]
    }
   ],
   "source": [
    "sampling_interval = 3\n",
    "systematic_sample = df.iloc[::sampling_interval]\n",
    "\n",
    "print(\"Systematic Sample:\")\n",
    "print(systematic_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23ae3c-6852-4cf7-8156-2a3405780caa",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "- We have a time series dataset with timestamps as the index.\n",
    "- We specify the sampling interval (`sampling_interval`) as every 3rd data point.\n",
    "- We perform systematic sampling by selecting every 3rd data point from the time series using the `iloc` indexer with the step size specified by the sampling interval.\n",
    "\n",
    "Systematic sampling is useful for time series data because it ensures that samples are evenly spaced throughout the time series, providing a representative sample of the entire dataset. This can be beneficial for various analyses and modeling tasks, such as trend analysis, forecasting, and anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cca549-b95f-4d3d-b3a5-f966b46e67f7",
   "metadata": {},
   "source": [
    "## Cluster Sampling\n",
    "\n",
    "Suppose we have a dataset with a 'population_id' column representing different clusters. Let's create a sample dataset for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5021e4f-9989-4353-943f-a6e91a25953b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population_id</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    population_id  feature1  feature2 class\n",
       "0               1         1        11     A\n",
       "1               1         2        12     A\n",
       "2               1         3        13     A\n",
       "3               2         4        14     B\n",
       "4               2         5        15     B\n",
       "5               2         6        16     B\n",
       "6               3         7        17     B\n",
       "7               3         8        18     B\n",
       "8               3         9        19     B\n",
       "9               4        10        20     B\n",
       "10              4        11        21     B\n",
       "11              4        12        22     B"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'population_id': [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n",
    "    'feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'feature2': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
    "    'class': ['A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba48017-767e-408b-bda8-f4ea485b450f",
   "metadata": {},
   "source": [
    "Then, we randomly select 'num_clusters_to_sample' clusters from the unique population IDs.  Finally, we filter the dataframe to include only the selected clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38576f35-e28e-427f-bf45-5fd5a139ea76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Sample:\n",
      "    population_id  feature1  feature2 class\n",
      "0               1         1        11     A\n",
      "1               1         2        12     A\n",
      "2               1         3        13     A\n",
      "9               4        10        20     B\n",
      "10              4        11        21     B\n",
      "11              4        12        22     B\n"
     ]
    }
   ],
   "source": [
    "clusters_to_sample = np.random.choice(df['population_id'].unique(), 2, replace=False)\n",
    "cluster_sample = df[df['population_id'].isin(clusters_to_sample)]\n",
    "\n",
    "print(\"Cluster Sample:\")\n",
    "print(cluster_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060dfb74-0230-436f-a1e5-4da448b7e3f0",
   "metadata": {},
   "source": [
    "## Cluster Sampling with Imbalanced Data\n",
    "\n",
    "In this example:\n",
    "\n",
    "- We have an imbalanced dataset with two classes ('A' and 'B').\n",
    "- We calculate the probabilities of selecting each cluster based on the class distribution.\n",
    "- We then use these probabilities to select clusters, ensuring that clusters containing minority classes have a higher chance of being selected.\n",
    "- Finally, we filter the dataframe to include only the rows corresponding to the selected clusters.\n",
    "\n",
    "By adjusting the cluster selection probabilities based on class distribution, we can ensure that the resulting cluster sample is more representative of the entire dataset, even in the presence of class imbalance.\n",
    "\n",
    "Let us calculate probabilities of selecting clusters based on class distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb599be4-410c-4852-9e88-6e97ecfc97a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "population_id\n",
       "1    0.25\n",
       "2    0.25\n",
       "3    0.25\n",
       "4    0.25\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distribution = df['population_id'].value_counts(normalize=True)\n",
    "cluster_probabilities = class_distribution / class_distribution.sum()\n",
    "cluster_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b2d7ee-e852-41ac-85d3-2b18bc331d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "population_id\n",
       "1    0.5\n",
       "4    0.5\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_distribution = cluster_sample['population_id'].value_counts(normalize=True)\n",
    "sample_probabilities = sample_distribution / sample_distribution.sum()\n",
    "sample_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe6473e-ba9f-426d-9d5c-cfeb3eba8a2d",
   "metadata": {},
   "source": [
    "## Stratified Sampling\n",
    "\n",
    "Suppose we have a dataset with a 'target' column representing different classes. Let's create a sample dataset for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16db40cb-0cd2-46c8-bba8-bce7ca34df7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2 target\n",
       "0         1        11      A\n",
       "1         2        12      A\n",
       "2         3        13      B\n",
       "3         4        14      B\n",
       "4         5        15      B\n",
       "5         6        16      C\n",
       "6         7        17      C\n",
       "7         8        18      C\n",
       "8         9        19      C\n",
       "9        10        20      C"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'feature2': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    'target': ['A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999e5213-265a-4327-9db6-2736b0227aca",
   "metadata": {},
   "source": [
    "Stratified sampling using train_test_split from sklearn. We specify the 'stratify' parameter to ensure that the sampling is stratified based on the 'target' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65809470-54d7-4f9b-8f89-82f9b31a768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.25, stratify=df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1b4ef9f-89ff-427b-8af5-ae50bc70afe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "   feature1  feature2 target\n",
      "5         6        16      C\n",
      "1         2        12      A\n",
      "6         7        17      C\n",
      "3         4        14      B\n",
      "4         5        15      B\n",
      "9        10        20      C\n",
      "7         8        18      C\n",
      "\n",
      "Test Set:\n",
      "   feature1  feature2 target\n",
      "8         9        19      C\n",
      "0         1        11      A\n",
      "2         3        13      B\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set:\")\n",
    "print(train)\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d1d528-04a1-4472-be8e-d75caf429208",
   "metadata": {},
   "source": [
    "## Stratified sampling with imbalanced data\n",
    "\n",
    "Stratified sampling is a method used to ensure that different subgroups within a population are adequately represented in the sample. This is particularly useful when certain subgroups are underrepresented in the dataset, and we want to ensure that our sample reflects the diversity of the population.\n",
    "\n",
    "In the example above\n",
    "\n",
    "- We have a dataset with two features ('feature1' and 'feature2') and a target variable ('target').\n",
    "- We use the `train_test_split` function from the `sklearn.model_selection` module to split the dataset into training and test sets.\n",
    "- We specify the `stratify` parameter and pass the 'target' column to indicate that we want to perform stratified sampling based on the 'target' variable.\n",
    "- The `test_size` parameter specifies the proportion of the dataset to include in the test split.\n",
    "- Finally, we print the training and test sets to observe the distribution of classes in both sets.\n",
    "\n",
    "By using stratified sampling, we ensure that the distribution of classes in the training and test sets closely resembles the distribution of classes in the original dataset. This helps in building more robust and generalizable machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f9c0f0-266f-44f7-9d96-26088d5e7ad3",
   "metadata": {},
   "source": [
    "## Stratified Cluster Sampling\n",
    "\n",
    "Stratified cluster sampling combines the principles of stratified sampling and cluster sampling. In this method, the population is first divided into homogeneous subgroups or strata based on certain characteristics (similar to stratified sampling). Then, within each stratum, clusters are randomly selected, and all individuals within the selected clusters are included in the sample (similar to cluster sampling). This approach ensures that the sample is representative of the entire population, with each subgroup and cluster being adequately represented.\n",
    "\n",
    "Suppose we have a dataset with a 'population_id' column representing different clusters and a 'stratum' column representing different strata.  Let's create a sample dataset for demonstration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1ea94f5-bf66-4039-bab2-161243ead79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population_id</th>\n",
       "      <th>stratum</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    population_id stratum  feature1  feature2\n",
       "0               1       A         1        11\n",
       "1               1       A         2        12\n",
       "2               1       B         3        13\n",
       "3               2       B         4        14\n",
       "4               2       B         5        15\n",
       "5               2       C         6        16\n",
       "6               3       C         7        17\n",
       "7               3       C         8        18\n",
       "8               3       D         9        19\n",
       "9               4       D        10        20\n",
       "10              4       D        11        21\n",
       "11              4       D        12        22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'population_id': [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n",
    "    'stratum': ['A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'D', 'D', 'D', 'D'],\n",
    "    'feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'feature2': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a922f9a-7d2d-4646-b3a5-802bd4d76fcc",
   "metadata": {},
   "source": [
    "Suppose we want to sample 2 clusters from each stratum. We first group the dataframe by stratum, initialize an empty dataframe to store the cluster sample and  iterate over each stratum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "821afb5a-e93d-4836-8be3-f07e2b741830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified Cluster Sample:\n",
      "    population_id stratum  feature1  feature2\n",
      "0               1       A         1        11\n",
      "1               1       A         2        12\n",
      "2               1       B         3        13\n",
      "6               3       C         7        17\n",
      "7               3       C         8        18\n",
      "9               4       D        10        20\n",
      "10              4       D        11        21\n",
      "11              4       D        12        22\n"
     ]
    }
   ],
   "source": [
    "num_clusters_to_sample_per_stratum = 1\n",
    "grouped = df.groupby('stratum')\n",
    "cluster_sample = pd.DataFrame()\n",
    "\n",
    "for stratum, group in grouped:\n",
    "    # Select clusters from the current stratum\n",
    "    clusters_to_sample = np.random.choice(group['population_id'].unique(), num_clusters_to_sample_per_stratum, replace=False)\n",
    "    # Filter the dataframe to include only the selected clusters from the current stratum\n",
    "    stratum_cluster_sample = group[group['population_id'].isin(clusters_to_sample)]\n",
    "    # Concatenate the current stratum cluster sample with the overall cluster sample\n",
    "    cluster_sample = pd.concat([cluster_sample, stratum_cluster_sample])\n",
    "\n",
    "print(\"Stratified Cluster Sample:\")\n",
    "print(cluster_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c21156-cc52-447a-bab7-ec03a6222aa0",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "- We have a dataset with a 'population_id' column representing different clusters and a 'stratum' column representing different strata.\n",
    "- We want to sample a certain number of clusters from each stratum.\n",
    "- We group the dataframe by stratum using the groupby function.\n",
    "- Then, for each stratum, we randomly select clusters and filter the dataframe to include only the selected clusters from that stratum.\n",
    "- Finally, we concatenate the cluster samples from all strata to obtain the overall stratified cluster sample.\n",
    "\n",
    "By using stratified cluster sampling, we ensure that the resulting sample represents the diversity of the entire population, with each stratum and cluster being adequately represented in the sample. This approach is particularly useful when there are significant differences between subgroups in the population and when the population is naturally clustered into groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364b8a00-0f3f-4384-a0db-a0b16653f27a",
   "metadata": {},
   "source": [
    "## Stratified cluster sampling with imbalanced data \n",
    "\n",
    "When dealing with imbalanced datasets, stratified cluster sampling can help ensure that both the minority and majority classes are adequately represented in the sample. Here's how stratified cluster sampling can be analyzed in the case of imbalanced datasets:\n",
    "\n",
    "1. **Stratification based on Class Distribution**: In the case of an imbalanced dataset, we can stratify the population based on the class distribution. This means that each stratum will contain a mix of samples from all classes, with the proportion of samples from each class reflecting the overall class distribution in the dataset.\n",
    "\n",
    "2. **Cluster Selection within Strata**: Within each stratum, we can perform cluster sampling to select clusters for inclusion in the sample. By randomly selecting clusters within each stratum, we ensure that the sample is representative of the entire population, with each class being adequately represented in the sample.\n",
    "\n",
    "3. **Adjustment for Imbalance**: Depending on the severity of the class imbalance, we may need to adjust the cluster selection probabilities to ensure that clusters containing minority classes have a higher chance of being selected. This helps prevent the minority classes from being underrepresented or excluded from the sample.\n",
    "\n",
    "Suppose we have an imbalanced dataset with a 'class' column representing different classes.  Let's illustrate stratified cluster sampling in the case of an imbalanced dataset using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42da5d6b-8291-4b47-bc80-5797c8e1e57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population_id</th>\n",
       "      <th>stratum</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    population_id stratum class\n",
       "0               1       A     A\n",
       "1               1       A     A\n",
       "2               1       B     A\n",
       "3               2       B     B\n",
       "4               2       B     B\n",
       "5               2       C     B\n",
       "6               3       C     B\n",
       "7               3       C     B\n",
       "8               3       D     B\n",
       "9               4       D     B\n",
       "10              4       D     B\n",
       "11              4       D     B"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'population_id': [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n",
    "    'stratum': ['A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'D', 'D', 'D', 'D'],\n",
    "    'class': ['A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d741a5b-aae5-4299-b9ad-bc402436eabb",
   "metadata": {},
   "source": [
    "Suppose we want to sample 1 cluster from each stratum. First, let us calculate class distribution within each stratum, initialize an empty dataframe to store the cluster sample and then iterate over each stratum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e33b1ca-5659-4554-bc73-f9dc3998dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified Cluster Sample:\n",
      "   population_id stratum class\n",
      "0              1       A     A\n",
      "1              1       A     A\n",
      "3              2       B     B\n",
      "4              2       B     B\n",
      "6              3       C     B\n",
      "7              3       C     B\n",
      "8              3       D     B\n"
     ]
    }
   ],
   "source": [
    "num_clusters_to_sample_per_stratum = 1\n",
    "stratum_class_distribution = df.groupby('stratum')['class'].value_counts(normalize=True)\n",
    "cluster_sample = pd.DataFrame()\n",
    "\n",
    "for stratum, group in df.groupby('stratum'):\n",
    "    unique_pop_ids = group['population_id'].unique()\n",
    "    cluster_probabilities = [stratum_class_distribution.get((stratum, group[group['population_id'] == pop_id]['class'].iloc[0]), 0) for pop_id in unique_pop_ids]\n",
    "    cluster_probabilities /= np.sum(cluster_probabilities)\n",
    "    clusters_to_sample = np.random.choice(unique_pop_ids, num_clusters_to_sample_per_stratum, replace=False, p=cluster_probabilities)\n",
    "    stratum_cluster_sample = group[group['population_id'].isin(clusters_to_sample)]\n",
    "    cluster_sample = pd.concat([cluster_sample, stratum_cluster_sample])\n",
    "\n",
    "print(\"Stratified Cluster Sample:\")\n",
    "print(cluster_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21df731c-b423-4bcc-8ec9-93f66de8b309",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "- We have an imbalanced dataset with two classes ('A' and 'B') and a 'stratum' column representing different strata.\n",
    "- We calculate the class distribution within each stratum.\n",
    "- We adjust the cluster selection probabilities based on the class distribution within each stratum.\n",
    "- We then randomly select clusters within each stratum, ensuring that clusters containing minority classes have a higher chance of being selected.\n",
    "- Finally, we concatenate the cluster samples from all strata to obtain the overall stratified cluster sample.\n",
    "\n",
    "By adjusting the cluster selection probabilities based on the class distribution, we ensure that the resulting sample is more representative of the entire population, even in the presence of class imbalance. This helps prevent bias and ensures that the model trained on the sample is more robust and generalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ca5ef-12c1-46a1-87e5-6f9491cf307a",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithms in the Context of Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712b4077-f52b-4f43-b5fc-a8077ac32ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment1(model, X, y, ts=0.25):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ts, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29821550-6c59-4997-b08b-b972d5e8bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment2(model, X, y):\n",
    "    validation = RepeatedStratifiedKFold(n_splits=10, n_repeats=5)\n",
    "    res = {}\n",
    "    for method in ['accuracy', 'precision', 'recall']:\n",
    "        val_scores = cross_val_score(model, X, y, scoring=method, cv=validation)\n",
    "        score = np.mean(val_scores)\n",
    "        sdev = sem(val_scores)\n",
    "        df = len(val_scores)-1\n",
    "        res.update({method: t.interval(0.95, df, loc=score, scale=sdev)})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5ff5ddb-d461-4c9d-ba13-7badd8f5a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000, n_features=10, n_classes=2, weights=[0.9, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a057370-2c0d-40d3-b96c-b90cd6763fb3",
   "metadata": {},
   "source": [
    "Model with parameter `class_weight='balanced'` automatically assign weights inversely proportional to class frequencies in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7d462dc-7a51-41ca-9ec9-6c3204c806a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1119\n",
      "           1       0.89      0.89      0.89       131\n",
      "\n",
      "    accuracy                           0.98      1250\n",
      "   macro avg       0.94      0.94      0.94      1250\n",
      "weighted avg       0.98      0.98      0.98      1250\n",
      "\n",
      "{'accuracy': (0.967875587861214, 0.9719644121387858), 'precision': (0.8272643954240908, 0.8527766079898911), 'recall': (0.8682202363501702, 0.8919103877427182)}\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(class_weight='balanced')\n",
    "print(experiment1(lr_model, X, y))\n",
    "print(experiment2(lr_model, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db4be892-2b84-450f-b46d-f871edd67ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1119\n",
      "           1       0.92      0.83      0.87       131\n",
      "\n",
      "    accuracy                           0.97      1250\n",
      "   macro avg       0.95      0.91      0.93      1250\n",
      "weighted avg       0.97      0.97      0.97      1250\n",
      "\n",
      "{'accuracy': (0.9785669086180637, 0.9818330913819364), 'precision': (0.9286104359707654, 0.9483821462596995), 'recall': (0.8599480265352959, 0.8857413783993922)}\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(class_weight='balanced',kernel='rbf')\n",
    "print(experiment1(svm_model, X, y))\n",
    "print(experiment2(svm_model, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e15ce34-a86f-4dfa-b2fe-9b8e97e117e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1120\n",
      "           1       0.89      0.87      0.88       130\n",
      "\n",
      "    accuracy                           0.98      1250\n",
      "   macro avg       0.94      0.93      0.93      1250\n",
      "weighted avg       0.97      0.98      0.98      1250\n",
      "\n",
      "{'accuracy': (0.9716003008000278, 0.974879699199972), 'precision': (0.8507813484531916, 0.8720198671068073), 'recall': (0.868835265583604, 0.8905116139519549)}\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(class_weight='balanced')\n",
    "print(experiment1(dt_model, X, y))\n",
    "print(experiment2(dt_model, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a65b39a1-dc19-4f03-a0be-19e6548458e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/local/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nn_model = keras.Sequential([\n",
    "      keras.layers.Dense(32, activation='relu', input_shape=(X.shape[-1],)),\n",
    "      keras.layers.Dropout(0.25),\n",
    "      keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "nn_model.compile(\n",
    "    optimizer=keras.optimizers.Adamax(learning_rate=1e-1),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e3ae4e0-a49b-4551-85cf-a0cb036586af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - binary_accuracy: 0.8449 - loss: 0.1235  \n",
      "Epoch 2/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9370 - loss: 0.0133\n",
      "Epoch 3/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9529 - loss: 0.0114\n",
      "Epoch 4/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9649 - loss: 0.0111\n",
      "Epoch 5/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9655 - loss: 0.0112\n",
      "Epoch 6/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9604 - loss: 0.0121\n",
      "Epoch 7/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9671 - loss: 0.0102\n",
      "Epoch 8/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9645 - loss: 0.0110\n",
      "Epoch 9/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9633 - loss: 0.0108\n",
      "Epoch 10/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9696 - loss: 0.0098\n",
      "Epoch 11/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9742 - loss: 0.0085\n",
      "Epoch 12/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9698 - loss: 0.0093\n",
      "Epoch 13/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9682 - loss: 0.0086\n",
      "Epoch 14/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9663 - loss: 0.0111\n",
      "Epoch 15/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9669 - loss: 0.0101\n",
      "Epoch 16/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9711 - loss: 0.0096\n",
      "Epoch 17/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9691 - loss: 0.0085\n",
      "Epoch 18/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9764 - loss: 0.0072\n",
      "Epoch 19/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - binary_accuracy: 0.9698 - loss: 0.0091\n",
      "Epoch 20/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9692 - loss: 0.0104\n",
      "Epoch 21/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9670 - loss: 0.0085\n",
      "Epoch 22/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9758 - loss: 0.0071\n",
      "Epoch 23/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9689 - loss: 0.0098\n",
      "Epoch 24/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9713 - loss: 0.0072\n",
      "Epoch 25/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9752 - loss: 0.0078  \n",
      "Epoch 26/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9729 - loss: 0.0087  \n",
      "Epoch 27/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9665 - loss: 0.0095\n",
      "Epoch 28/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9667 - loss: 0.0090    \n",
      "Epoch 29/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9705 - loss: 0.0092\n",
      "Epoch 30/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9726 - loss: 0.0095\n",
      "Epoch 31/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9747 - loss: 0.0084\n",
      "Epoch 32/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9717 - loss: 0.0087\n",
      "Epoch 33/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9738 - loss: 0.0084\n",
      "Epoch 34/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9664 - loss: 0.0093\n",
      "Epoch 35/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9719 - loss: 0.0096\n",
      "Epoch 36/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9741 - loss: 0.0095\n",
      "Epoch 37/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9716 - loss: 0.0083\n",
      "Epoch 38/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9742 - loss: 0.0072\n",
      "Epoch 39/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9773 - loss: 0.0069    \n",
      "Epoch 40/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9792 - loss: 0.0069\n",
      "Epoch 41/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9772 - loss: 0.0071\n",
      "Epoch 42/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9800 - loss: 0.0061    \n",
      "Epoch 43/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9755 - loss: 0.0079\n",
      "Epoch 44/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9748 - loss: 0.0076  \n",
      "Epoch 45/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9783 - loss: 0.0069\n",
      "Epoch 46/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9781 - loss: 0.0073\n",
      "Epoch 47/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9748 - loss: 0.0069  \n",
      "Epoch 48/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9749 - loss: 0.0083\n",
      "Epoch 49/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9803 - loss: 0.0074\n",
      "Epoch 50/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9734 - loss: 0.0085\n",
      "Epoch 51/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9765 - loss: 0.0077  \n",
      "Epoch 52/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9812 - loss: 0.0081\n",
      "Epoch 53/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9769 - loss: 0.0076\n",
      "Epoch 54/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9793 - loss: 0.0064\n",
      "Epoch 55/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9827 - loss: 0.0056\n",
      "Epoch 56/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9748 - loss: 0.0079\n",
      "Epoch 57/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9760 - loss: 0.0069\n",
      "Epoch 58/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9759 - loss: 0.0071\n",
      "Epoch 59/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9800 - loss: 0.0066\n",
      "Epoch 60/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9739 - loss: 0.0076\n",
      "Epoch 61/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9786 - loss: 0.0067\n",
      "Epoch 62/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9817 - loss: 0.0060    \n",
      "Epoch 63/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9777 - loss: 0.0075\n",
      "Epoch 64/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9796 - loss: 0.0073\n",
      "Epoch 65/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9757 - loss: 0.0072    \n",
      "Epoch 66/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9774 - loss: 0.0073\n",
      "Epoch 67/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9763 - loss: 0.0070\n",
      "Epoch 68/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9813 - loss: 0.0062\n",
      "Epoch 69/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9767 - loss: 0.0073\n",
      "Epoch 70/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9775 - loss: 0.0068\n",
      "Epoch 71/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9835 - loss: 0.0053    \n",
      "Epoch 72/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9745 - loss: 0.0078\n",
      "Epoch 73/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9780 - loss: 0.0069\n",
      "Epoch 74/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9817 - loss: 0.0065\n",
      "Epoch 75/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9764 - loss: 0.0074\n",
      "Epoch 76/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9765 - loss: 0.0070\n",
      "Epoch 77/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9788 - loss: 0.0066\n",
      "Epoch 78/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9783 - loss: 0.0066\n",
      "Epoch 79/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9838 - loss: 0.0057 \n",
      "Epoch 80/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9799 - loss: 0.0063\n",
      "Epoch 81/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9742 - loss: 0.0073\n",
      "Epoch 82/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9780 - loss: 0.0080\n",
      "Epoch 83/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9777 - loss: 0.0065\n",
      "Epoch 84/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9775 - loss: 0.0069\n",
      "Epoch 85/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9801 - loss: 0.0070\n",
      "Epoch 86/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9826 - loss: 0.0059\n",
      "Epoch 87/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9805 - loss: 0.0063\n",
      "Epoch 88/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9829 - loss: 0.0058    \n",
      "Epoch 89/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9789 - loss: 0.0062\n",
      "Epoch 90/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9811 - loss: 0.0064\n",
      "Epoch 91/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9831 - loss: 0.0059\n",
      "Epoch 92/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9859 - loss: 0.0047  \n",
      "Epoch 93/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9792 - loss: 0.0072\n",
      "Epoch 94/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9800 - loss: 0.0064    \n",
      "Epoch 95/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9750 - loss: 0.0066\n",
      "Epoch 96/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9820 - loss: 0.0060\n",
      "Epoch 97/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9824 - loss: 0.0062\n",
      "Epoch 98/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9801 - loss: 0.0073\n",
      "Epoch 99/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9779 - loss: 0.0067\n",
      "Epoch 100/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9802 - loss: 0.0066\n",
      "Epoch 101/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9805 - loss: 0.0066\n",
      "Epoch 102/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9746 - loss: 0.0066\n",
      "Epoch 103/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9770 - loss: 0.0065\n",
      "Epoch 104/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9788 - loss: 0.0068    \n",
      "Epoch 105/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9758 - loss: 0.0075\n",
      "Epoch 106/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9816 - loss: 0.0058\n",
      "Epoch 107/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9825 - loss: 0.0057    \n",
      "Epoch 108/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9803 - loss: 0.0062  \n",
      "Epoch 109/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9841 - loss: 0.0059\n",
      "Epoch 110/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9797 - loss: 0.0056\n",
      "Epoch 111/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9845 - loss: 0.0055\n",
      "Epoch 112/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9827 - loss: 0.0065\n",
      "Epoch 113/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9813 - loss: 0.0070\n",
      "Epoch 114/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9777 - loss: 0.0063  \n",
      "Epoch 115/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9799 - loss: 0.0061\n",
      "Epoch 116/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9832 - loss: 0.0057    \n",
      "Epoch 117/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9786 - loss: 0.0066\n",
      "Epoch 118/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9809 - loss: 0.0061    \n",
      "Epoch 119/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - binary_accuracy: 0.9780 - loss: 0.0062\n",
      "Epoch 120/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9795 - loss: 0.0067  \n",
      "Epoch 121/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9837 - loss: 0.0057\n",
      "Epoch 122/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9822 - loss: 0.0061\n",
      "Epoch 123/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - binary_accuracy: 0.9799 - loss: 0.0057\n",
      "Epoch 124/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9809 - loss: 0.0060\n",
      "Epoch 125/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9811 - loss: 0.0060\n",
      "Epoch 126/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9793 - loss: 0.0086\n",
      "Epoch 127/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9794 - loss: 0.0061\n",
      "Epoch 128/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9760 - loss: 0.0082\n",
      "Epoch 129/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9807 - loss: 0.0060  \n",
      "Epoch 130/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9816 - loss: 0.0056\n",
      "Epoch 131/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9813 - loss: 0.0053    \n",
      "Epoch 132/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9825 - loss: 0.0063\n",
      "Epoch 133/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9826 - loss: 0.0054\n",
      "Epoch 134/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9820 - loss: 0.0056\n",
      "Epoch 135/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9819 - loss: 0.0065\n",
      "Epoch 136/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9813 - loss: 0.0053  \n",
      "Epoch 137/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9827 - loss: 0.0051\n",
      "Epoch 138/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9821 - loss: 0.0054\n",
      "Epoch 139/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9806 - loss: 0.0058\n",
      "Epoch 140/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9801 - loss: 0.0057\n",
      "Epoch 141/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9770 - loss: 0.0065\n",
      "Epoch 142/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9760 - loss: 0.0076\n",
      "Epoch 143/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9798 - loss: 0.0064\n",
      "Epoch 144/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9819 - loss: 0.0057\n",
      "Epoch 145/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9811 - loss: 0.0055\n",
      "Epoch 146/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9819 - loss: 0.0053\n",
      "Epoch 147/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9819 - loss: 0.0055\n",
      "Epoch 148/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9824 - loss: 0.0057\n",
      "Epoch 149/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9814 - loss: 0.0059\n",
      "Epoch 150/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9804 - loss: 0.0060    \n",
      "Epoch 151/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9803 - loss: 0.0062\n",
      "Epoch 152/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9804 - loss: 0.0055    \n",
      "Epoch 153/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9816 - loss: 0.0078\n",
      "Epoch 154/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9795 - loss: 0.0067\n",
      "Epoch 155/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9854 - loss: 0.0047    \n",
      "Epoch 156/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9782 - loss: 0.0061\n",
      "Epoch 157/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9802 - loss: 0.0059\n",
      "Epoch 158/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9802 - loss: 0.0058\n",
      "Epoch 159/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9823 - loss: 0.0053\n",
      "Epoch 160/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9827 - loss: 0.0055\n",
      "Epoch 161/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9843 - loss: 0.0058\n",
      "Epoch 162/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9802 - loss: 0.0056\n",
      "Epoch 163/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9820 - loss: 0.0056\n",
      "Epoch 164/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9792 - loss: 0.0063    \n",
      "Epoch 165/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9792 - loss: 0.0063\n",
      "Epoch 166/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9834 - loss: 0.0054\n",
      "Epoch 167/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9786 - loss: 0.0066\n",
      "Epoch 168/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9789 - loss: 0.0057\n",
      "Epoch 169/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9878 - loss: 0.0045\n",
      "Epoch 170/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9841 - loss: 0.0056  \n",
      "Epoch 171/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9834 - loss: 0.0051    \n",
      "Epoch 172/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9842 - loss: 0.0056\n",
      "Epoch 173/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9795 - loss: 0.0064\n",
      "Epoch 174/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9818 - loss: 0.0054    \n",
      "Epoch 175/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9799 - loss: 0.0059    \n",
      "Epoch 176/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9838 - loss: 0.0050\n",
      "Epoch 177/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9793 - loss: 0.0062    \n",
      "Epoch 178/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9852 - loss: 0.0065\n",
      "Epoch 179/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9809 - loss: 0.0058\n",
      "Epoch 180/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9806 - loss: 0.0058\n",
      "Epoch 181/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9817 - loss: 0.0056\n",
      "Epoch 182/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9820 - loss: 0.0054    \n",
      "Epoch 183/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9828 - loss: 0.0057\n",
      "Epoch 184/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9809 - loss: 0.0057\n",
      "Epoch 185/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9817 - loss: 0.0055  \n",
      "Epoch 186/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9835 - loss: 0.0046\n",
      "Epoch 187/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9826 - loss: 0.0053\n",
      "Epoch 188/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9793 - loss: 0.0061\n",
      "Epoch 189/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9801 - loss: 0.0055\n",
      "Epoch 190/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9840 - loss: 0.0052\n",
      "Epoch 191/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9801 - loss: 0.0071\n",
      "Epoch 192/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9780 - loss: 0.0061\n",
      "Epoch 193/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9819 - loss: 0.0050\n",
      "Epoch 194/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9816 - loss: 0.0065\n",
      "Epoch 195/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9802 - loss: 0.0052  \n",
      "Epoch 196/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9859 - loss: 0.0045    \n",
      "Epoch 197/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9834 - loss: 0.0051\n",
      "Epoch 198/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9820 - loss: 0.0054\n",
      "Epoch 199/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9792 - loss: 0.0092\n",
      "Epoch 200/200\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9843 - loss: 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x763dfced5b20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y.reshape(y.shape[-1],1,), test_size=0.25, stratify=y)\n",
    "nn_model.fit(X_train, y_train, epochs=200, batch_size=50, class_weight={0: 0.95, 1: 0.05})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1573d152-820e-4899-92b9-886d47c0531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      1119\n",
      "           1       0.00      0.00      0.00       131\n",
      "\n",
      "    accuracy                           0.90      1250\n",
      "   macro avg       0.45      0.50      0.47      1250\n",
      "weighted avg       0.80      0.90      0.85      1250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/local/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kaygun/local/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kaygun/local/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(nn_model.predict(X_test),axis=1)\n",
    "print(classification_report(y_test.reshape(y_test.shape[0]), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7a928-9f05-4ae9-8a27-b37a2c01af6b",
   "metadata": {},
   "source": [
    "## A Real Dataset\n",
    "\n",
    "The dataset is taken from [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccec16fd-783a-4eb5-be10-2f68b4ab2778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24535ec8-4854-44a3-a62b-0fc1d3c7cb2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#del data['Time']\n",
    "del data['Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "154c3880-c529-4168-8227-9e2ce9132238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V20       V21  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ...  0.251412 -0.018307   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.524980  0.247998   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  1.475829  0.213454   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.059616  0.214205   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.001396  0.232045   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.127434  0.265245   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.382948  0.261057   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
       "284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
       "284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
       "284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
       "284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 29 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4223c55-aeed-4287-97f0-9ca8f189b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y = data.iloc[:,:28], data.iloc[:,28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ba3e388-2a9c-40cf-ad13-e723de56ee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     71079\n",
      "           1       0.06      0.93      0.11       123\n",
      "\n",
      "    accuracy                           0.97     71202\n",
      "   macro avg       0.53      0.95      0.55     71202\n",
      "weighted avg       1.00      0.97      0.98     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=10000, solver='liblinear', class_weight='balanced')\n",
    "print(experiment1(lr_model, data_x, data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3704edc-df53-434b-93da-3babc7167d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.29      0.77      0.43       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.65      0.88      0.71     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(class_weight='balanced', kernel='rbf')\n",
    "print(experiment1(svm_model, data_x, data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0a055c8-8220-4ed0-a4c6-01765afc148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.75      0.69      0.72       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.87      0.85      0.86     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(class_weight='balanced')\n",
    "print(experiment1(dt_model, data_x, data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fa85cbfd-7759-43f5-8a2c-03e22ab97aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/local/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nn_model = keras.Sequential([\n",
    "      keras.layers.Dense(16, activation='relu', input_dim=data_x.shape[1]),\n",
    "      keras.layers.Dropout(0.5),\n",
    "      keras.layers.Dense(32, activation='softmax'),\n",
    "      keras.layers.Dropout(0.25),\n",
    "      keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "nn_model.compile(\n",
    "    optimizer=keras.optimizers.Adamax(learning_rate=5e-2),\n",
    "    loss=keras.losses.BinaryFocalCrossentropy(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e498eb4-f104-4633-8033-eb1d87cc9955",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.25, stratify=data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0541798a-3c7d-44ff-98b9-27f06ab09ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9963 - loss: 0.0062\n",
      "Epoch 2/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0020\n",
      "Epoch 3/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0016\n",
      "Epoch 4/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0017\n",
      "Epoch 5/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9987 - loss: 0.0019\n",
      "Epoch 6/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0015\n",
      "Epoch 7/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0015\n",
      "Epoch 8/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0015\n",
      "Epoch 9/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0015\n",
      "Epoch 10/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0015\n",
      "Epoch 11/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0015\n",
      "Epoch 12/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0014\n",
      "Epoch 13/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0014\n",
      "Epoch 14/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0016\n",
      "Epoch 15/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0014\n",
      "Epoch 16/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0014\n",
      "Epoch 17/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0013\n",
      "Epoch 18/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0016\n",
      "Epoch 19/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9990 - loss: 0.0013\n",
      "Epoch 20/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9990 - loss: 0.0014\n",
      "Epoch 21/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0016\n",
      "Epoch 22/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0016\n",
      "Epoch 23/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0017\n",
      "Epoch 24/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0016\n",
      "Epoch 25/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9991 - loss: 0.0014\n",
      "Epoch 26/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9990 - loss: 0.0015\n",
      "Epoch 27/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0014\n",
      "Epoch 28/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0014\n",
      "Epoch 29/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9990 - loss: 0.0014\n",
      "Epoch 30/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9987 - loss: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0015\n",
      "Epoch 32/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9987 - loss: 0.0015\n",
      "Epoch 33/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0015\n",
      "Epoch 34/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0016\n",
      "Epoch 35/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0016\n",
      "Epoch 36/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9990 - loss: 0.0015\n",
      "Epoch 37/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9987 - loss: 0.0016\n",
      "Epoch 38/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9987 - loss: 0.0019\n",
      "Epoch 39/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0016\n",
      "Epoch 40/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0017\n",
      "Epoch 41/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9987 - loss: 0.0016\n",
      "Epoch 42/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0019\n",
      "Epoch 43/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9990 - loss: 0.0015\n",
      "Epoch 44/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9990 - loss: 0.0016\n",
      "Epoch 45/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0017\n",
      "Epoch 46/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0016\n",
      "Epoch 47/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9990 - loss: 0.0015\n",
      "Epoch 48/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9989 - loss: 0.0015\n",
      "Epoch 49/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9988 - loss: 0.0017\n",
      "Epoch 50/50\n",
      "\u001b[1m2137/2137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - binary_accuracy: 0.9990 - loss: 0.0014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x763dbff29910>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.fit(X_train, y_train, epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf59e9d3-40e1-4f94-a122-1b0f6f88d324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2226/2226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 702us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.00      0.00      0.00       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.50      0.50      0.50     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/local/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kaygun/local/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kaygun/local/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(nn_model.predict(X_test),axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4293164e-bff7-4219-a4af-627890b89f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71079,     0],\n",
       "       [  123,     0]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981de2ac-9c8b-4001-be3d-5cab180dc5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
